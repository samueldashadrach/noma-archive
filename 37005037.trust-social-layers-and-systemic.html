<p>Trust is complex. As mentioned briefly in my article on <a href="https://noma.substack.com/p/deep-dive-into-the-oracle-problem">the oracle problem</a>, trust can largely be broken down into:</p><ul><li><p>Economic - incentives are set up such that any economically rational actor will perform desirable actions</p></li><li><p>Moral / normative - incentives and social norms are set up such that an actor will perform certain actions because those are moral or based on expected norms that actors don’t often wish to deviate from</p></li><li><p>Reputation-based - incentives are set up such that actors prefer maintaining existing “trusted” relationships and reputation as part of a larger system of incentives.</p></li></ul><p>Blockchains are designed with the explicit purpose of relying more on cryptoeconomic guarantees, and less on moral or reputation-based ones. The motivations behind these are presumably:</p><ul><li><p>Less systemic risk</p></li><li><p>More certainty over the degree of risk</p></li></ul><p>when dealing with a purely cryptoeconomic world.</p><h3>Systemic risk</h3><p>For instance, if a store chooses to not place a security guard at the gate, it is assuming that the vast majority of people are moral enough to not want to rob the store. Or even if they place one security guard, they’re assuming that the number of people willing to execute an armed robbery to overpower this single guard is small. When banks give loans without full collateralisation they’re assuming all the loans won’t default at the same time. When Aave grants you a loan with 75% collateral factor, it is assuming that the price of that collateral won’t crash by more than 25% between two oracle updates. When courts have an upper limit to the number of cases they will be willing to hear in a given period of time, they’re assuming they won’t be DDOSed by meaningless lawsuits that slow down the judiciary and prevent justice from being delivered.</p><p>All systems in the real world take on some degree of systemic risk, i.e., unlikely events that could crash large systems if those events took place. And sometimes such events do take place. For instance the 2008 financial crisis was caused due to systemic overestimation of the amount of liquidity present for mortage-backed securities. Civil wars have been caused precisely by a small (but significant) group of individuals disrupting existing systems that have not been designed with a mechanism to withstand such disruptions.</p><p>Fully guarding against tail risk is impossible. For instance it would be impossible to grant a loan with even a 10% collateral factor (borrow $10 of USD against $100 of ETH) unless somebody assumed that the probability of ETH crashing 90% rapidly was low enough to be worth assuming this risk. No third party could offset this risk, as that person too would now have to provide a lot of excess collateral for no reward. Tail risk can usually only be transferred from one party to another. Eliminating it involves absurd capital inefficiency, atleast in a market context. Even in a non-market context, not assuming any systemic risk slows down systems very significantly. For instance if the judiciary placed a strong upper limit for how many cases they could hear, and auctioned rights to these slots, then a vast variety of contracts and trusted relationships could simply never be established because they don’t have this judiciary to arbitrate for them. (As an aside, this is exactly what blockchains do by specifying blocksize limits).</p><h3>Certainty over risk</h3><p>Systemic risk is often very hard to quantify. For instance a nation-wide earthquake is an uninsurable systemic risk for which only rough estimates based on historical data can be made. The odds of an armed robbery taking place at a store is again, something that can only be estimated very imprecisely with historical data. The amount of liquidity present in the open market for an asset is not fully measurable either. Sure, you can measure the current amount of liquidity, but there is no guarantee this liquidity will be present when you actually needed, nor is there an easy way to estimate the odds of it. (Although ofcourse, an entire science has evolved to measure this risk)</p><h3>Trusted relationships</h3><p>Most activity in the real world takes place through trusted relationships. Companies assume that Google won’t take down their data in order to crash their stock. (This bears superficial resemblance to a data unavailability attack.) Clients assume that their doctors or lawyers won’t betray them for financial gain.</p><p>Part of the formation of such relationships involves a repeated game, where both actors perform actions that are trustworthy. Each such action helps shift the Bayesian priors over the probability of the other actor being malicious, in the mind of the actor who is choosing to trust. Over time such relationships can grow close. Since constructing such relationships takes time and effort, they are finite in number, and people prefer to maintain them for future circumstances rather than betray (even if these futures are currently unknown).</p><p><a href="https://ncase.me/trust/">The evolution of trust</a> by Nicky Case is a game that explains the evolution of such trust and priors very well.</p><h3>Who is a trusting entity?</h3><p>At the base level, trust is between individuals (and not blobs of capital as some blockchain analyses would like you to think). Beyond this, trust is established between systems - each of which are composed of their own individual trusted relationships. For instance when users trust Google to not make their data unavailable, they’re trusting both a complex set of relationships inside of Google’s corporate structure that make such an attack difficult, as well the relationship shared by Google with other businesses, with the judiciary, and broader society.  Each of these other business and judicial systems too is trusted because of complex trusted relationships inside of them.</p><h3>Social layer in ethereum</h3><p>A system that relies purely on cryptoeconomic incentives to create trust is strictily inferior to one that allows trusted relationships to form. Restricting the toolkit used to forge relationships and move towards common goals restricts the pace at which one can move towards those goals.</p><p>Systemic risk in these trusted relationships, the challenge is when this systemic risk pervades into the base layer itself. Ethereum has allowed significant systemic risk to creep in, in the process of innovating and enabling new forms of activity that bitcoin deoesn’t. Whether such systemic risk creep is an inevitable consequence of enabling more types of useful activity on a blockchain is an open question. I am of the strong opinion that it is, at very least due to necessity of oracles and the trusted relationships they benefit from (covered in my <a href="https://noma.substack.com/p/deep-dive-into-the-oracle-problem">oracle article</a> or later in this article).</p><h3>Systemic risk in hard forking</h3><p>Hard forks via social coordination are the last layer of defence when defending blockchains. This social layer inevitably has a lot of systemic risk and inefficiency. For instance, popularity on social media will play a significant role in shaping public opinion over which fork is to be used and which one is to be dumped. Anonymous parties are effectively excluded from such discourse on any social platforms that exlcudes users.</p><p>There is significant capture of this process by the core ethereum researchers - users are more likely to simply use the fork on which all subsequent research and innovation is going to be conducted, as evident in the fall of ETC.</p><p>There is also very significant capture of this process by dapps and trust sources. Consider a hypothetical where Circle deems one of the two ethereum forks as canonical, allowing USDC redemptions to fiat only on that chain, and not on the other. This leads to significant volatility and crashes in the markets on the other fork. Chainlink may then respond to by also declaring a canonical fork. LINK value on the other fork crashes, at which point some guy from China scoops up all the LINK for cheap and feeds bogus values, effectively draining all dapps such as Aave and Synthetix. Dapps too eventually abandon this fork. Effectively a few actors have decided the canonical fork for the entire DeFi ecosystem.</p><p>That fork will continue to be functional for its original purposes of transferring ETH, but all additional functionality will be removed in unison due to their tight integrations with each other. As long as dapps are deemed the primary use case of ethereum, however, this essentually deems the canonical fork socially.</p><p>So when ethereum is <a href="https://blog.ethereum.org/2015/02/14/subjectivity-exploitability-tradeoff/">chaos-theoretically guaranteed to protect your grandmother’s funds</a> as elucidated by Vitalik, this chaos theoretic process may actually be captured by  very few entities.</p><h3>Systemic risk in not running nodes</h3><p>A significant number of ethereum users don’t run nodes. They maintain trusted relationships with entities such as Infura (metamask defaults to Infura), the Graph (which is built into dapp backends and may be used to construct transaction payloads) and etherscan. Each month that goes with Infura not attempting to fed false data increases everyone’s Bayesian priors that Infura will probably not serve incorrect data in the future, although this systemic risk persists.</p><p>One might argue that ethereum is not about getting everyone to run a node, but providing them the optionality to run one if they don’t have a trusted relationships. However if everyone establisbhes identical trusted relationships via small sets of entities, this makes the system as a whole incapable of resolving hard forks as democratically in the time of an emergency.</p><h3>Systemic risk due to MEV capture</h3><p>Flashbots has centralised the network for the capture of MEV. All ethereum traffic now flows through a bunch of servers maintained by the Flashbots team. All miners are now forced to somewhat deanonymise themselves and establish a line with these servers - this could in turn serve as a focal point of coordination among miners. (And yes, such miner coordination is bad because it is a pre-requisite for any type of attack.)</p><p>Miner incentives have been changed from the original gasprice based ones, to the payments provided by bundles. The original incentives against DOS were cryptoeconomic (gas paid for failed transactions), today they’re API ratelimits on the flashbot servers. This is also a benefit for users, as users don’t want to pay gas for failed transactions. Gasless transactions have evolved for users (MistX, Cowswap) as users would rather prefer a centralised server sorting and discarding transactions without payment, rather than paying miners to come to consensus on this. </p><p>Certain entities can <em>promise </em>not to extract MEV and commit to transaction orderings, especially on layer two where users can pick block producers. This could be a central entity such as what Arbitrum and Optimism will initially start with, or something like Chainlink’s fair sequencing. Accepting a promise that a certain block producer will commit to orderings when the time comes, is a trusted relationship that poses systemic risk as it make break down and devolve back to maximal MEV extraction. A world that assumes no MEV extraction will take place could face serious unintended consequences when it devolves back into one that extracts MEV, imposing systemic risk.</p><p>Mempools can grow unbounded when transactions pay zero gas, and it is likely that access to these mempools and relayers could prove as further centralisation. Same applies to the computational capacity needed to extract maximal MEV on unbounded mempools. All such centralisation comes with systemic risk and risk of regulatory capture.</p><h3>Systemic risk as a consequence of scalability</h3><p>Increasing transactions per second inevitably forces centralisation, as decentralised systems running on desktop computers cannot transmit that much data. All rollups have centralised (although possibly rotating) block producers with higher bandwidth and computational requirements. All ethereum traffic will soon flow through them, and we will soon trust them to maintain uptime and not censor users’s IP addresses.</p><h3>Systemic risk due to oracles </h3><p>All oracle systems - be it MakerDAO, Chainlink or UMA - have weaker cryptoeconomic guarantees than those of the underlying base layer. They however secure a very significant amount of activity and capital today. Cryptoeconomically they assume a honest majority, as a malicious majority may have incentive to attack the system. Some degree of trust beyond the cryptoeconomic will always be preferred, as entities make themselves public and beholden to legal action if they act maliciously. Relying on legal systems simply converts systemic risk from the actors being immoral to that of the legal system failing or capturing regulations for the system.</p><h3>Systemic risk due to stake delegation</h3><p>ETH 2.0 has significant systemic risk in the form of stake delegation, as covered by <a href="https://noma.substack.com/p/eth-20-monetary-policy-and-delegation">this article</a>. The vast majority of ETH holders are not technically and politically motivated enough to run their validators, this will cause them to delegate their ETH to known entities with varying levels of trust in such relationships.</p><p>This centralisation could in turn increase risk of regulatory capture of the entire ethereum ecosystem, with nation states demanding certain thefts or illegal transactions to be censored or slowed down, for instance. Regulatory capture can in theory go far beyond this, however, as KYC/AML can eventually be demanded, first for all stakers and eventually for all users.</p><h3>Conclusion</h3><p>Ethereum has opened itself to very significant amounts of systemic risk, that in my opinion, is an inevitably consequence of supporting far more types of economic activity than bitcoin.</p><p>Increased focus may need to be paid in identifying and quantifying such risks. This could also draw from the general body of economic and game-theoretic research and its attempts to formalise how trusted relationships develop, what their guarantees are, and what forms of risk they pose.</p><p>Blockchains attempted to solve uncertainty over risk in trusted relationships by assuming no trusted relationships exist, this will soon prove an inadequate approach. Instead we will now have to further our research on how trusted relationships can work and eliminate our gaps in our understanding of the same.</p>