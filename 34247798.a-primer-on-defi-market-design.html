<p>DeFi has spawned a whole bunch of new market designs - some of which seem very different from those in TradFi. Truth is DeFi is its own unique design space with its own principles. Let’s explore these.</p><p></p><h3>Gas efficiency drives design</h3><p>Gas limits exist because we want to bound the total amount of computation and storage someone needs to possess to act as a node in the ethereum network (and therefore know what is going on). This means you need to run decentralised exchanges, yield aggregators and so much more for everyone on the planet on a single desktop computer, so that anyone can check what is going on.</p><p>This in turn means you need to minimise the number of computational and storage operations required. A protocol that consumes less gas will outcompete a similar protocol that uses more gas, unless the latter has other competitive advantages. This is one of the strongest competitive advantages. Even if only a few people know about your more efficient model, the ones who are using it will end up increasing gasprice - because they are able to extract more economic value per unit of computation and storage (gas). This puts pressure on everyone else to move to this model.</p><h3></h3><h3>Fixed cost versus running cost is a tradeoff - favour minimising running cost</h3><p>This is one of the most important principles of this article.</p><p><code>Fixed cost = reserve storage, initialise values in storage, initialise code in storage</code></p><p><code>Running cost = change values in storage, computations</code></p><p>Typically, over a long enough period of time, the running cost of any design significantly exceeds the fixed cost. Therefore you must prefer higher fixed costs over running costs. You can even socialise this fixed cost among all the future users of your protocol. A protocol minting new tokens to cover this is a lazy but efficient way of socialising the cost.</p><p>So you minimise the amount of storage updates and computation that has to be done on a per-interaction basis, even if it means higher costs to deploy and initialise.</p><p>Reserving storage is currently a fixed cost, but it may become a running cost in the future, because it is, after all, a running cost for node who run the network. If a <a href="https://ethereum-magicians.org/t/weak-statelessness-and-or-state-expiry-coming-soon/5453">state expiry scheme</a>, there may reach a point where designs need to be changed because it costs too much to reserve more storage (fixed cost is too high).</p><p></p><h3>Use on-chain computation and storage on demand rather than in anticipation</h3><p>In TradFi limit order books, market makers make limit orders in anticipation of new market orders. As orders get filled, market makers need more computation to figure out where to place new orders. Most of these orders never get filled, but they are worth placing anyway because placing orders is cheap.</p><p>In an AMM, this computation is only done on demand, i.e., when someone wants to fill the order.</p><p>Prefer doing computation or updating storage only when it is necessary to close the deal.</p><p></p><h3>Running costs operate at various time scales</h3><p>Again, to take the example of a market maker - if you offer them multiple pools with multiple strategies (Uniswap v Sushiswap v Balancer v on-chain limit orderbook), they will want to change their strategy with time. <a href="https://uniswap.org/blog/uniswap-v3/">Uniswap v3</a> is a great example of this.</p><p>A market maker may, for instance, want to change the price range in which they offer liquidity, based on the observed volatility of the pair or a credit rating someone elese provides. These vary with time. You could off-load this cost to the person filling the order. Have the person filling the order compute the volatility or query the credit rating, then compute the market maker’s strategy, and then fill the order. This is a running cost on a per-interaction basis. Alternatively you can have the market maker themselves do the computation and update the values periodically, as and when they want to. This is also a running cost, but it is less frequent.</p><p><code>Running costs in a smaller timeframe cost more over those in a bigger timeframe - prefer them only if the economic value generated by doing so exceeds the cost.</code></p><p>This could mean you do not update marketmaking strategies on a per-interaction basis, update them less frequently instead.</p><p></p><h3>Mid-scale running costs can be automated - prefer off-chain computation</h3><p>Updates such as the above - changing price range based on volatility, or even just liquidating overleveraged borrowed positions - are mid-scale running costs that can be automated. I say mid-scale because it does not happen on a per-interaction basis. One way to automate is to provide an incentive for someone to run this update - this is why liquidations have incentives, so does running <a href="https://docs.keep3r.network/">keepers for yearn</a>. </p><p>Keepers need to be compensated for both the on-chain cost of triggering each update, and the cost of doing off-chain computation to check when to trigger it. Both costs are at two different scales - one is on a per-update basis which depends on the frequency of your update, and the other is on a per-update-check basis, which is frequently just a per-interaction basis. Strictly speaking. however, per-update-check basis does not need to be the same as a per-interaction basis. For instance if you are running a light client, you only need to check when Alice makes a trade and not every block, if you are deciding whether to liquidate Alice. </p><p>You should prefer off-chain computation wherever possible, as it is far cheaper than on-chain computation. Doing the off-chain computation yourself for your positions is the ideal option. Delegating off-chain computation to anonymous users means you may still need to do some on-chain computation to authorise them - at the very least, an incentive check.</p><p>Having permissionless keepers assumes the existence of atleast one economically rational keeper, which is a reasonable assumption. You can increase the pressure towards economic rationality by requiring liquidators or keepers to stake a bond which gets slashed if someone catches them not making updates when they are expected to.</p><p></p><h3>Think in terms of orderbooks and TradFi</h3><p>Orderbooks are a great model to visualise how trades take place, I find them more intuitive that bonding curves. A bonding curve or AMM can be represented as a set of auto-updating limit orders. For each 1% increase in price, there is a certain amount of assets that get traded. This amount is simply a limit order within that 1% price range. Basic calculus tells you how to convert an AMM to a set of limit orders. The set of orders get updated after every interaction as per current designs (ofcourse this doesn’t have to be the case).</p><p>Ofcourse this does not mean you actually implement orderbooks, they are just a good mental model.</p><p>TradFi is very capital efficient at most tasks because they do not have kind of computational and storage requirements imposed by on-chain design. Therefore pay very strong attention to how actors typically operate the other. The benefits DeFi has are transparency, more composability and less regulations. But the single benefit of TradFi design having more storage and compute power is often powerful than all of these other benefits combined.</p><p></p><h3>Bigger orders can afford more gas</h3><p>This is a very obvious principle that has been largely ignored in DeFi design today. Larger orders can be more complex, and consume more storage and computation, because they generate economic value. Smaller orders, on the other hand, will prefer to be simpler so that they consume less gas. Even if this means they are less capital-efficient or offer worse prices.</p><p>This is why the smallest traders will still prefer a single atomic swap to clear their “dust” positions - as this is cheaper than even Uniswap.</p><p>The problem occurs when you have large orders on one side matching with small orders on the other side, this is where tradeoffs emerge.</p><p></p><h3>Pool actions wherever possible</h3><p>If hundred users all want to do the same action (or similar actions), you can save a lot of gas by having them pool their assets together and conduct this action. This is why most DeFi protocols are peer-to-pool or pool-to-pool instead of peer-to-peer. AMMs are pool-to-peer, lending protocols are pool-to-peer, <a href="https://creamdotfinance.medium.com/introducing-the-iron-bank-bab9417c9a">iron bank</a> is pool-to-pool, yield aggregators are pool-to-pool.</p><p><code>Almost all actions can eventually be pooled and executed pool-to-pool, as there are very few interactions users want to make that are truly unique.</code></p><p>A unique interaction is worth facilitating over a similar interaction but pooled - if the difference in economic value of both actions exceeds the difference in gas costs of both actions.</p><p>The other main reason to support peer interactions is impatience - people don’t want to wait long enough to pool. For instance suppose there exists a computationally intensive pool - like Uniswap v3 or Balancer, or perhaps even more complex. Users who want to buy a token in small amounts would be better off pooling their assets in a mini-DAO, executing the trade as a pool, and then withdrawing from the pool if they want to use the assets elsewhere. However if they are impatient (operate at low time scales), they won’t wait to batch. As gas costs keep going up there will be pressure on users to operate at lower time scales and batch their interactions, in order to save on gas. Using a rollup to buy L1 assets or tokenised positions in L1 vaults (buying yUSDC, cUSDC) is also a form of such batching.</p><p></p><h3>People want to operate in different time frames</h3><p>A continuation of the previous point.</p><p><code>A significant reason why markets exist in the first place is because people operate at different time frames.</code></p><p>Market makers are essentially a speculative arbitrage between lower time frame orders and higher time frame orders.</p><p>Loans are offered in various time frames (or atleast they should be). Actors will emerge to hedge rates for different time frames against each other, this leads to the formation of a <a href="https://en.wikipedia.org/wiki/Yield_curve">yield curve</a>.</p><p></p><h3>Pools and liquidity are a moat</h3><p>Liquidity is a moat every bit as real as Facebook having a moat over user attention. A moat is said to exist when U(1 + 2) &gt; U(1) + U(2), this favours 1 and 2 existing in the same place. Most physical resources prefer to be pooled and form monopolies, liquidity is no different.</p><p><a href="https://www.investopedia.com/ask/answers/07/securitization.asp">Securitisation</a> is great way to create liquidity in otherwise illiquid assets.</p><p>Creating liquidity requires people to devote intellectual capital to study those assets and conditions. More liquidity allows for more leverage, it also gives traders more faith that they will not be “locked” into their positions because liquidity is pulled. Until now, we don’t have a concept of locked or guaranteed liquidity, therefore the existence of sufficient liquidity for an asset is a behavioural phenomena partly backed by "faith”.</p><p>DeFi puts even more pressure towards pools because of gas costs which are saved when actions are pooled.</p><p>Moats are by nature, anti-competitive, and people will prefer a slightly worse design with more liquidity over a better design with less liquidity.</p><p><code>The anti-competitive nature of moats does raise interesting questions regarding free and unregulated markets such as DeFi, and whether such highly free markets are a societal good or maximise competition.</code></p><p>As long as you are a market designer however, it makes sense to take advantage of and account for such moats.</p><p></p><h3></h3>